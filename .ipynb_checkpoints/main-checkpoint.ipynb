{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from toolbox import *\n",
    "cuda_device = torch.device(\"cuda:1\")\n",
    "from scipy.spatial.distance import pdist, squareform \n",
    "from model import *\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'dataset': datasets.MNIST}\n",
    "trainset, trainloader = load_trainset(**kwargs)\n",
    "testset, testloader =  load_testset(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set, train_set = random_split(trainset, [2000, len(trainset)-2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100,\n",
    "                                         shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_item = train_set.indices\n",
    "labeled_trainset = L_set_MNIST([],[], transform_train)\n",
    "net = Net().to(cuda_device)\n",
    "net2 = Net().to(cuda_device)\n",
    "optimizer = optim.Adam(params = net.parameters(),  lr = 0.0008)\n",
    "optimizer2 = optim.Adam(params = net2.parameters(),  lr = 0.0008)\n",
    "best_net_model = None\n",
    "best_model_accuracy = 0\n",
    "acquisition_size = 20\n",
    "sub_sample_pool_size = 2000\n",
    "test_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size = 28, scale = (0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_list of the train_set\n",
    "train_index_list = train_set.indices.clone().numpy()\n",
    "#create the initial trainset with 20 images\n",
    "sample_indexes = available_item[:20]\n",
    "for items in sample_indexes: \n",
    "    labeled_trainset.update(trainset.data[items], trainset.targets[items])\n",
    "train_index_list = np.setdiff1d(train_index_list,sample_indexes)\n",
    "#Performs Active Learning for 50 step\n",
    "for step in range(50):\n",
    "    if step < 1:\n",
    "        sample_indexes = available_item[(step*acquisition_size):((step+1)*acquisition_size)]\n",
    "        for items in sample_indexes: \n",
    "            labeled_trainset.update(trainset.data[items], trainset.targets[items])\n",
    "        #re_load_train_loader\n",
    "        trainloader = torch.utils.data.DataLoader(labeled_trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "        train_index_list = np.setdiff1d(train_index_list,sample_indexes)           \n",
    "    else:    \n",
    "        current_output = None\n",
    "        last_output  = None\n",
    "        for iteration in range(20):\n",
    "            np.random.shuffle(train_index_list)\n",
    "            #select a randomized sub-sample pool\n",
    "            sample = trainset.data[train_index_list[:sub_sample_pool_size]]\n",
    "            sample_transformed = torch.zeros([sub_sample_pool_size, 1, 28,28])\n",
    "\n",
    "            for i in range(len(sample)):\n",
    "                sample_transformed[i] = dual_transform_train(Image.fromarray(sample[i].numpy(), mode='L'))   \n",
    "            with torch.no_grad():\n",
    "                net.train()\n",
    "                net2.train()\n",
    "                net_o0= net((sample_transformed).to(cuda_device))\n",
    "                net2_o0 = net2((sample_transformed).to(cuda_device))\n",
    "                net_o0_copy= net((sample_transformed).to(cuda_device))\n",
    "                net2_o0_copy = net2((sample_transformed).to(cuda_device))\n",
    "                largest_distance = 0\n",
    "                for samples in range(len(net_o0)):\n",
    "                    #calculate distance\n",
    "                    distance_val_1 = pdist(torch.cat((normalizer(net_o0[samples].cpu()).unsqueeze(0), normalizer(net2_o0[samples].cpu()).unsqueeze(0)), dim = 0))\n",
    "                    distance_val_2 = pdist(torch.cat((normalizer(net_o0_copy[samples].cpu()).unsqueeze(0), normalizer(net2_o0_copy[samples].cpu()).unsqueeze(0)), dim = 0))\n",
    "                    distance_val = distance_val_1+distance_val_2  \n",
    "                    \n",
    "                    if distance_val > largest_distance:\n",
    "                        largest_distance = distance_val\n",
    "                        temp_index = samples\n",
    "                        largest_index = train_index_list[samples]\n",
    "            train_index_list = np.setdiff1d(train_index_list, largest_index)\n",
    "            labeled_trainset.update(trainset.data[largest_index], trainset.targets[largest_index])\n",
    "    #train on the newly_accquire data       \n",
    "    trainloader = torch.utils.data.DataLoader(labeled_trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "    for i in range(30):\n",
    "        train(1,net, optimizer, trainloader, cuda_device)\n",
    "        train(1,net2, optimizer2, trainloader, cuda_device)\n",
    "        best_model_accuracy, best_net_model = test_val(net, best_net_model, val_loader, best_model_accuracy, cuda_device) \n",
    "    net = load_network(net, best_net_model)\n",
    "    test_result.append(test_test(step, net, testloader, cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"MNist_dual_val.npy\", np.array(result_list))\n",
    "np.save(\"MNist_dual_test.npy\", np.array(test_result_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(data, save_id):\n",
    "    a = collections.Counter(data)\n",
    "    plt.bar(a.keys(), a.values(), 0.8)\n",
    "    plt.ylabel('Number of instances per class')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Class id')\n",
    "    plt.ylim(top = 200)\n",
    "    plt.show\n",
    "    num = str(save_id)\n",
    "    plt.savefig('Plot/distribution_' + num + '.eps', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_per_class = []\n",
    "for item in labeled_trainset.labelset:\n",
    "    item_per_class.append(item.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(temp_list1, \"Mnist_dist_dual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = test_acc_per_class( net, testloader, cuda_device)\n",
    "class_accuracy = [0 for i in range(10)]\n",
    "for i in range(10):\n",
    "    class_accuracy[i] = class_count[1][i]/class_count[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = [i for i in range(10)]\n",
    "plt.bar(class_id, class_accuracy  )\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.grid(True)\n",
    "plt.ylim(top = 1)\n",
    "plt.ylim(bottom = 0.8)\n",
    "plt.xlabel('Class id')\n",
    "plt.savefig('Plot/Mnist_dist_acc_dual.eps') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
